{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range, input\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\chunx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_class.brown import get_sentences_with_word2idx_limit_vocab, get_sentences_with_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_probs(sentences, V, start_idx, end_idx, smoothing=1):\n",
    "  # structure of bigram probability matrix:\n",
    "  # (last word, current word) --> probability\n",
    "  # use add-1 smoothing, ignore this from the END token\n",
    "  bigram_probs = np.ones((V, V)) * smoothing\n",
    "  for sentence in sentences:\n",
    "    for i in range(len(sentence)):\n",
    "      \n",
    "      if i == 0:\n",
    "        # beginning word\n",
    "        bigram_probs[start_idx, sentence[i]] += 1\n",
    "      else:\n",
    "        # middle word\n",
    "        bigram_probs[sentence[i-1], sentence[i]] += 1\n",
    "\n",
    "      # for the final word, update the bigram for last -> current, AND current -> END token\n",
    "      if i == len(sentence) - 1:\n",
    "        # final word\n",
    "        bigram_probs[sentence[i], end_idx] += 1\n",
    "\n",
    "  # normalize the counts along the rows to get probabilities\n",
    "  bigram_probs /= bigram_probs.sum(axis=1, keepdims=True)\n",
    "  return bigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START inf\n",
      "END inf\n",
      "man inf\n",
      "paris inf\n",
      "britain inf\n",
      "england inf\n",
      "king inf\n",
      "woman inf\n",
      "rome inf\n",
      "london inf\n",
      "queen inf\n",
      "italy inf\n",
      "france inf\n",
      "the 69971\n",
      ", 58334\n",
      ". 49346\n",
      "of 36412\n",
      "and 28853\n",
      "to 26158\n",
      "a 23195\n",
      "in 21337\n",
      "that 10594\n",
      "is 10109\n",
      "was 9815\n",
      "he 9548\n",
      "for 9489\n",
      "`` 8837\n",
      "'' 8789\n",
      "it 8760\n",
      "with 7289\n",
      "as 7253\n",
      "his 6996\n",
      "on 6741\n",
      "be 6377\n",
      "; 5566\n",
      "at 5372\n",
      "by 5306\n",
      "i 5164\n",
      "this 5145\n",
      "had 5133\n",
      "? 4693\n",
      "not 4610\n",
      "are 4394\n",
      "but 4381\n",
      "from 4370\n",
      "or 4206\n",
      "have 3942\n",
      "an 3740\n",
      "they 3620\n",
      "which 3561\n",
      "-- 3432\n",
      "one 3292\n",
      "you 3286\n",
      "were 3284\n",
      "her 3036\n",
      "all 3001\n",
      "she 2860\n",
      "there 2728\n",
      "would 2714\n",
      "their 2669\n",
      "we 2652\n",
      "him 2619\n",
      "been 2472\n",
      ") 2466\n",
      "has 2437\n",
      "( 2435\n",
      "when 2331\n",
      "who 2252\n",
      "will 2245\n",
      "more 2215\n",
      "if 2198\n",
      "no 2139\n",
      "out 2097\n",
      "so 1985\n",
      "said 1961\n",
      "what 1908\n",
      "up 1890\n",
      "its 1858\n",
      "about 1815\n",
      ": 1795\n",
      "into 1791\n",
      "than 1790\n",
      "them 1788\n",
      "can 1772\n",
      "only 1748\n",
      "other 1702\n",
      "new 1635\n",
      "some 1618\n",
      "could 1601\n",
      "time 1598\n",
      "! 1596\n",
      "these 1573\n",
      "two 1412\n",
      "may 1402\n",
      "then 1380\n",
      "do 1363\n",
      "first 1361\n",
      "any 1344\n",
      "my 1318\n",
      "now 1314\n",
      "such 1303\n",
      "like 1292\n",
      "our 1252\n",
      "over 1236\n",
      "me 1181\n",
      "even 1170\n",
      "most 1159\n",
      "made 1125\n",
      "also 1069\n",
      "after 1069\n",
      "did 1044\n",
      "many 1030\n",
      "before 1016\n",
      "must 1013\n",
      "af 996\n",
      "through 971\n",
      "back 966\n",
      "years 950\n",
      "where 937\n",
      "much 937\n",
      "your 923\n",
      "way 908\n",
      "well 897\n",
      "down 895\n",
      "should 888\n",
      "because 883\n",
      "each 877\n",
      "just 872\n",
      "those 850\n",
      "people 847\n",
      "mr. 844\n",
      "too 834\n",
      "how 834\n",
      "little 831\n",
      "state 807\n",
      "good 806\n",
      "very 796\n",
      "make 794\n",
      "world 787\n",
      "still 782\n",
      "see 772\n",
      "own 772\n",
      "men 763\n",
      "work 762\n",
      "long 752\n",
      "here 750\n",
      "get 749\n",
      "both 730\n",
      "between 730\n",
      "life 715\n",
      "being 712\n",
      "under 707\n",
      "never 697\n",
      "day 687\n",
      "same 686\n",
      "another 684\n",
      "know 683\n",
      "while 680\n",
      "last 676\n",
      "us 675\n",
      "might 672\n",
      "great 665\n",
      "old 661\n",
      "year 658\n",
      "off 639\n",
      "come 630\n",
      "since 628\n",
      "against 627\n",
      "go 626\n",
      "came 622\n",
      "right 613\n",
      "used 611\n",
      "take 610\n",
      "three 610\n",
      "himself 603\n",
      "states 603\n",
      "few 601\n",
      "house 591\n",
      "use 591\n",
      "during 585\n",
      "without 583\n",
      "again 577\n",
      "place 570\n",
      "american 569\n",
      "around 562\n",
      "however 552\n",
      "home 547\n",
      "small 542\n",
      "found 536\n",
      "mrs. 534\n",
      "1 527\n",
      "thought 517\n",
      "went 507\n",
      "say 504\n",
      "part 500\n",
      "once 499\n",
      "general 498\n",
      "high 497\n",
      "upon 495\n",
      "school 493\n",
      "every 491\n",
      "don't 489\n",
      "does 485\n",
      "got 482\n",
      "united 482\n",
      "left 480\n",
      "number 472\n",
      "course 465\n",
      "war 464\n",
      "until 461\n",
      "always 458\n",
      "away 456\n",
      "something 450\n",
      "fact 447\n",
      "2 446\n",
      "water 445\n",
      "though 440\n",
      "public 438\n",
      "less 437\n",
      "put 437\n",
      "think 433\n",
      "almost 432\n",
      "hand 431\n",
      "enough 430\n",
      "took 426\n",
      "far 426\n",
      "head 424\n",
      "yet 419\n",
      "government 418\n",
      "system 416\n",
      "set 414\n",
      "better 414\n",
      "told 413\n",
      "night 411\n",
      "nothing 411\n",
      "end 409\n",
      "why 404\n",
      "didn't 401\n",
      "called 401\n",
      "eyes 401\n",
      "find 400\n",
      "going 399\n",
      "look 399\n",
      "asked 398\n",
      "later 397\n",
      "knew 395\n",
      "point 395\n",
      "next 394\n",
      "program 394\n",
      "city 393\n",
      "business 393\n",
      "group 390\n",
      "give 389\n",
      "toward 386\n",
      "young 385\n",
      "let 384\n",
      "days 384\n",
      "room 384\n",
      "president 382\n",
      "side 381\n",
      "social 380\n",
      "present 377\n",
      "given 377\n",
      "several 377\n",
      "order 376\n",
      "national 375\n",
      "possible 374\n",
      "rather 373\n",
      "second 373\n",
      "face 371\n",
      "per 371\n",
      "among 370\n",
      "form 370\n",
      "often 369\n",
      "important 369\n",
      "things 368\n",
      "looked 367\n",
      "early 366\n",
      "white 365\n",
      "john 362\n",
      "case 362\n",
      "large 361\n",
      "four 360\n",
      "need 360\n",
      "big 360\n",
      "become 359\n",
      "within 359\n",
      "felt 357\n",
      "children 355\n",
      "along 355\n",
      "saw 352\n",
      "best 351\n",
      "church 348\n",
      "ever 344\n",
      "least 343\n",
      "power 342\n",
      "development 334\n",
      "seemed 333\n",
      "thing 333\n",
      "light 333\n",
      "family 331\n",
      "interest 330\n",
      "want 328\n",
      "members 325\n",
      "mind 325\n",
      "area 324\n",
      "country 324\n",
      "others 323\n",
      "although 321\n",
      "turned 320\n",
      "done 319\n",
      "open 318\n",
      "' 317\n",
      "god 316\n",
      "service 315\n",
      "problem 313\n",
      "certain 313\n",
      "kind 313\n",
      "different 312\n",
      "thus 312\n",
      "began 312\n",
      "door 312\n",
      "help 311\n",
      "sense 311\n",
      "means 310\n",
      "whole 309\n",
      "matter 308\n",
      "perhaps 307\n",
      "itself 304\n",
      "york 302\n",
      "it's 302\n",
      "times 300\n",
      "law 299\n",
      "human 299\n",
      "line 298\n",
      "above 296\n",
      "name 294\n",
      "example 292\n",
      "action 291\n",
      "company 290\n",
      "hands 289\n",
      "local 288\n",
      "show 288\n",
      "3 287\n",
      "whether 286\n",
      "five 286\n",
      "history 286\n",
      "gave 285\n",
      "today 284\n",
      "either 284\n",
      "act 283\n",
      "feet 283\n",
      "across 282\n",
      "taken 281\n",
      "past 281\n",
      "quite 281\n",
      "anything 280\n",
      "seen 279\n",
      "having 279\n",
      "death 277\n",
      "experience 276\n",
      "body 276\n",
      "week 275\n",
      "half 275\n",
      "really 275\n",
      "word 274\n",
      "field 274\n",
      "car 274\n",
      "words 274\n",
      "already 273\n",
      "themselves 270\n",
      "i'm 269\n",
      "information 269\n",
      "tell 268\n",
      "shall 268\n",
      "together 267\n",
      "college 267\n",
      "money 265\n",
      "period 265\n",
      "held 264\n",
      "keep 264\n",
      "sure 263\n",
      "probably 261\n",
      "free 259\n",
      "seems 259\n",
      "political 258\n",
      "real 258\n",
      "cannot 258\n",
      "behind 258\n",
      "question 257\n",
      "air 257\n",
      "office 255\n",
      "making 255\n",
      "brought 253\n",
      "miss 253\n",
      "whose 251\n",
      "special 250\n",
      "major 247\n",
      "heard 247\n",
      "problems 247\n",
      "federal 246\n",
      "became 246\n",
      "study 246\n",
      "ago 246\n",
      "moment 246\n",
      "available 245\n",
      "known 245\n",
      "result 244\n",
      "street 244\n",
      "economic 243\n",
      "boy 242\n",
      "position 241\n",
      "reason 241\n",
      "change 240\n",
      "south 240\n",
      "board 239\n",
      "individual 239\n",
      "job 238\n",
      "am 237\n",
      "society 237\n",
      "areas 236\n",
      "west 235\n",
      "close 234\n",
      "turn 233\n",
      "community 231\n",
      "true 231\n",
      "love 231\n",
      "court 230\n",
      "force 230\n",
      "full 230\n",
      "cost 229\n",
      "seem 229\n",
      "wife 228\n",
      "future 227\n",
      "age 227\n",
      "wanted 226\n",
      "voice 226\n",
      "department 225\n",
      "center 224\n",
      "control 223\n",
      "common 223\n",
      "policy 222\n",
      "necessary 222\n",
      "following 221\n",
      "front 221\n",
      "sometimes 221\n",
      "six 220\n",
      "girl 220\n",
      "clear 219\n",
      "further 218\n",
      "land 218\n",
      "provide 216\n",
      "feel 216\n",
      "party 216\n",
      "able 216\n",
      "mother 216\n",
      "music 216\n",
      "education 214\n",
      "university 214\n",
      "child 213\n",
      "effect 213\n",
      "students 213\n",
      "level 213\n",
      "run 212\n",
      "stood 212\n",
      "military 212\n",
      "town 212\n",
      "short 212\n",
      "morning 211\n",
      "total 211\n",
      "outside 210\n",
      "rate 209\n",
      "figure 209\n",
      "art 208\n",
      "century 207\n",
      "class 207\n",
      "washington 206\n",
      "4 206\n",
      "north 206\n",
      "usually 206\n",
      "plan 205\n",
      "leave 205\n",
      "therefore 205\n",
      "evidence 204\n",
      "top 204\n",
      "million 204\n",
      "sound 204\n",
      "black 203\n",
      "strong 202\n",
      "hard 202\n",
      "tax 201\n",
      "various 201\n",
      "says 200\n",
      "believe 200\n",
      "type 200\n",
      "value 200\n",
      "play 200\n",
      "surface 200\n",
      "soon 199\n",
      "mean 199\n",
      "near 198\n",
      "lines 198\n",
      "table 198\n",
      "peace 198\n",
      "modern 198\n",
      "road 197\n",
      "red 197\n",
      "book 197\n",
      "personal 196\n",
      "process 196\n",
      "situation 196\n",
      "minutes 196\n",
      "increase 195\n",
      "schools 195\n",
      "idea 195\n",
      "english 195\n",
      "alone 195\n",
      "women 195\n",
      "gone 195\n",
      "nor 195\n",
      "living 194\n",
      "america 194\n",
      "started 194\n",
      "longer 193\n",
      "dr. 192\n",
      "cut 192\n",
      "finally 191\n",
      "secretary 191\n",
      "nature 191\n",
      "private 191\n",
      "third 190\n",
      "months 189\n",
      "section 189\n",
      "greater 188\n",
      "call 188\n",
      "fire 187\n",
      "expected 187\n",
      "needed 187\n",
      "that's 187\n",
      "kept 186\n",
      "ground 186\n",
      "view 186\n",
      "values 186\n",
      "everything 185\n",
      "pressure 185\n",
      "dark 185\n",
      "basis 184\n",
      "space 184\n",
      "east 183\n",
      "father 183\n",
      "required 182\n",
      "union 182\n",
      "spirit 182\n",
      "complete 182\n",
      "except 181\n",
      "wrote 181\n",
      "i'll 181\n",
      "moved 181\n",
      "support 180\n",
      "return 180\n",
      "conditions 180\n",
      "recent 179\n",
      "attention 179\n",
      "late 179\n",
      "particular 179\n",
      "live 177\n",
      "hope 177\n",
      "costs 176\n",
      "else 176\n",
      "brown 176\n",
      "taking 175\n",
      "couldn't 175\n",
      "forces 175\n",
      "nations 175\n",
      "beyond 175\n",
      "stage 175\n",
      "read 174\n",
      "report 174\n",
      "coming 174\n",
      "hours 174\n",
      "person 174\n",
      "inside 174\n",
      "dead 174\n",
      "material 174\n",
      "instead 173\n",
      "lost 173\n",
      "heart 173\n",
      "looking 173\n",
      "low 173\n",
      "miles 173\n",
      "data 173\n",
      "added 172\n",
      "pay 172\n",
      "amount 172\n",
      "followed 172\n",
      "feeling 172\n",
      "1960 172\n",
      "single 172\n",
      "makes 172\n",
      "research 171\n",
      "including 171\n",
      "basic 171\n",
      "hundred 171\n",
      "move 171\n",
      "industry 171\n",
      "cold 171\n",
      "simply 171\n",
      "developed 170\n",
      "tried 170\n",
      "hold 169\n",
      "can't 169\n",
      "reached 169\n",
      "committee 168\n",
      "island 167\n",
      "defense 167\n",
      "equipment 167\n",
      "actually 166\n",
      "shown 166\n",
      "son 165\n",
      "central 165\n",
      "religious 165\n",
      "river 165\n",
      "getting 164\n",
      "st. 164\n",
      "beginning 164\n",
      "sort 164\n",
      "ten 164\n",
      "received 163\n",
      "& 163\n",
      "doing 163\n",
      "terms 163\n",
      "trying 163\n",
      "rest 163\n",
      "medical 162\n",
      "u.s. 162\n",
      "care 162\n",
      "especially 162\n",
      "friends 162\n",
      "picture 162\n",
      "indeed 162\n",
      "administration 161\n",
      "fine 161\n",
      "subject 161\n",
      "difficult 161\n",
      "building 160\n",
      "higher 160\n",
      "wall 160\n",
      "simple 160\n",
      "meeting 159\n",
      "walked 159\n",
      "floor 158\n",
      "foreign 158\n",
      "bring 158\n",
      "similar 157\n",
      "passed 157\n",
      "range 157\n",
      "paper 157\n",
      "property 156\n",
      "natural 156\n",
      "final 156\n",
      "training 156\n",
      "county 155\n",
      "police 155\n",
      "cent 155\n",
      "international 155\n",
      "growth 155\n",
      "market 155\n",
      "wasn't 154\n",
      "talk 154\n",
      "start 154\n",
      "written 154\n",
      "hear 153\n",
      "suddenly 153\n",
      "story 153\n",
      "issue 152\n",
      "congress 152\n",
      "needs 152\n",
      "10 152\n",
      "answer 152\n",
      "hall 152\n",
      "likely 151\n",
      "working 151\n",
      "countries 151\n",
      "considered 151\n",
      "you're 151\n",
      "earth 150\n",
      "sat 150\n",
      "purpose 149\n",
      "meet 149\n",
      "labor 149\n",
      "results 149\n",
      "entire 149\n",
      "happened 149\n",
      "william 148\n",
      "cases 148\n",
      "stand 148\n",
      "difference 148\n",
      "production 148\n",
      "hair 148\n",
      "involved 147\n",
      "fall 147\n",
      "stock 147\n",
      "food 147\n",
      "earlier 146\n",
      "increased 146\n",
      "whom 146\n",
      "particularly 146\n",
      "paid 145\n",
      "sent 145\n",
      "effort 145\n",
      "knowledge 145\n",
      "hour 145\n",
      "letter 145\n",
      "club 145\n",
      "using 145\n",
      "below 145\n",
      "thinking 145\n",
      "yes 144\n",
      "christian 144\n",
      "blue 143\n",
      "ready 143\n",
      "bill 143\n",
      "deal 143\n",
      "points 143\n",
      "trade 143\n",
      "certainly 143\n",
      "ideas 143\n",
      "industrial 143\n",
      "square 143\n",
      "boys 143\n",
      "methods 142\n",
      "addition 142\n",
      "method 142\n",
      "bad 142\n",
      "due 142\n",
      "5 142\n",
      "girls 142\n",
      "moral 142\n",
      "decided 141\n",
      "reading 141\n",
      "statement 141\n",
      "weeks 141\n",
      "neither 141\n",
      "nearly 141\n",
      "directly 141\n",
      "showed 141\n",
      "throughout 141\n",
      "according 140\n",
      "questions 140\n",
      "color 140\n",
      "kennedy 140\n",
      "anyone 140\n",
      "try 140\n",
      "services 139\n",
      "programs 139\n",
      "nation 139\n",
      "lay 139\n",
      "french 139\n",
      "size 138\n",
      "remember 138\n",
      "physical 138\n",
      "record 137\n",
      "member 137\n",
      "comes 137\n",
      "understand 137\n",
      "southern 137\n",
      "western 137\n",
      "strength 137\n",
      "population 136\n",
      "normal 136\n",
      "merely 135\n",
      "district 135\n",
      "volume 135\n",
      "concerned 135\n",
      "appeared 135\n",
      "temperature 135\n",
      "1961 134\n",
      "aid 134\n",
      "trouble 134\n",
      "trial 134\n",
      "summer 134\n",
      "direction 134\n",
      "ran 134\n",
      "sales 133\n",
      "list 133\n",
      "continued 133\n",
      "friend 133\n",
      "evening 133\n",
      "maybe 133\n",
      "literature 133\n",
      "generally 132\n",
      "association 132\n",
      "provided 132\n",
      "led 132\n",
      "army 132\n",
      "met 132\n",
      "influence 132\n",
      "opened 131\n",
      "former 131\n",
      "science 131\n",
      "student 131\n",
      "step 131\n",
      "changes 131\n",
      "chance 131\n",
      "husband 131\n",
      "hot 130\n",
      "series 130\n",
      "average 130\n",
      "works 130\n",
      "month 130\n",
      "cause 130\n",
      "effective 129\n",
      "george 129\n",
      "planning 129\n",
      "systems 129\n",
      "wouldn't 129\n",
      "direct 129\n",
      "soviet 129\n",
      "stopped 129\n",
      "wrong 129\n",
      "lead 129\n",
      "myself 129\n",
      "piece 129\n",
      "theory 129\n",
      "ask 128\n",
      "worked 128\n",
      "freedom 128\n",
      "organization 128\n",
      "clearly 128\n",
      "movement 128\n",
      "ways 128\n",
      "press 127\n",
      "somewhat 127\n",
      "spring 127\n",
      "efforts 127\n",
      "consider 127\n",
      "meaning 127\n",
      "bed 127\n",
      "fear 127\n",
      "lot 127\n",
      "treatment 127\n",
      "beautiful 127\n",
      "note 127\n",
      "forms 127\n",
      "placed 126\n",
      "hotel 126\n",
      "truth 126\n",
      "apparently 125\n",
      "degree 125\n",
      "groups 125\n",
      "he's 125\n",
      "plant 125\n",
      "carried 125\n",
      "wide 125\n",
      "i've 125\n",
      "respect 125\n",
      "man's 125\n",
      "herself 125\n",
      "numbers 125\n",
      "manner 124\n",
      "reaction 124\n",
      "easy 124\n",
      "farm 124\n",
      "immediately 123\n",
      "running 123\n",
      "approach 123\n",
      "game 123\n",
      "recently 123\n",
      "larger 123\n",
      "lower 123\n",
      "charge 122\n",
      "couple 122\n",
      "de 122\n",
      "daily 122\n",
      "eye 122\n",
      "performance 122\n",
      "feed 122\n",
      "oh 122\n",
      "march 121\n",
      "persons 121\n",
      "understanding 121\n",
      "arms 121\n",
      "opportunity 121\n",
      "c 121\n",
      "blood 121\n",
      "additional 120\n",
      "j. 120\n",
      "technical 120\n",
      "fiscal 120\n",
      "radio 120\n",
      "described 120\n",
      "stop 120\n",
      "progress 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 119\n",
      "test 119\n",
      "chief 119\n",
      "reported 119\n",
      "served 119\n",
      "based 119\n",
      "main 119\n",
      "determined 119\n",
      "image 119\n",
      "decision 119\n",
      "window 119\n",
      "religion 119\n",
      "aj 118\n",
      "gun 118\n",
      "responsibility 118\n",
      "middle 118\n",
      "europe 118\n",
      "british 118\n",
      "character 118\n",
      "learned 117\n",
      "horse 117\n",
      "writing 117\n",
      "appear 117\n",
      "s. 117\n",
      "account 117\n",
      "ones 116\n",
      "serious 116\n",
      "activity 116\n",
      "types 116\n",
      "green 116\n",
      "length 116\n",
      "lived 115\n",
      "audience 115\n",
      "letters 115\n",
      "returned 115\n",
      "obtained 115\n",
      "nuclear 115\n",
      "specific 115\n",
      "corner 115\n",
      "forward 115\n",
      "activities 115\n",
      "slowly 115\n",
      "doubt 114\n",
      "6 114\n",
      "justice 114\n",
      "moving 114\n",
      "latter 114\n",
      "gives 114\n",
      "straight 114\n",
      "hit 114\n",
      "plane 114\n",
      "quality 114\n",
      "design 114\n",
      "obviously 114\n",
      "operation 113\n",
      "plans 113\n",
      "shot 113\n",
      "seven 113\n",
      "a. 113\n",
      "choice 113\n",
      "poor 113\n",
      "staff 113\n",
      "function 113\n",
      "figures 113\n",
      "parts 113\n",
      "stay 113\n",
      "saying 113\n",
      "include 113\n",
      "15 113\n",
      "born 113\n",
      "pattern 113\n",
      "30 112\n",
      "cars 112\n",
      "whatever 112\n",
      "sun 112\n",
      "faith 111\n",
      "pool 111\n",
      "hospital 110\n",
      "corps 110\n",
      "wish 110\n",
      "lack 110\n",
      "completely 110\n",
      "heavy 110\n",
      "waiting 110\n",
      "speak 110\n",
      "ball 110\n",
      "standard 110\n",
      "extent 110\n",
      "visit 109\n",
      "democratic 109\n",
      "firm 109\n",
      "income 109\n",
      "ahead 109\n",
      "deep 109\n",
      "there's 109\n",
      "language 109\n",
      "principle 109\n",
      "none 108\n",
      "price 108\n",
      "designed 108\n",
      "indicated 108\n",
      "analysis 108\n",
      "distance 108\n",
      "expect 108\n",
      "established 108\n",
      "products 108\n",
      "effects 108\n",
      "Vocab size: 1001\n",
      "REAL: `` and you know i can do it '' . SCORE: -3.3287794819206784\n",
      "FAKE: almost among both entire france hit down party sat most SCORE: -8.293616940073218\n",
      "Enter your sentence:\n",
      "this is carrie\n",
      "Sorry, the words are not in the vocabulary\n",
      "Continue? [Y/n]none of them is true\n",
      "REAL: UNKNOWN UNKNOWN : SCORE: -2.686266787907858\n",
      "FAKE: john foreign lived SCORE: -7.767125632557919\n",
      "Enter your sentence:\n",
      "distance\n",
      "SCORE: -10.447988855392557\n",
      "Continue? [Y/n]expect\n",
      "REAL: he walked past the UNKNOWN into a UNKNOWN room with UNKNOWN full of big , UNKNOWN UNKNOWN from floor to UNKNOWN all around the UNKNOWN . SCORE: -3.677107720974475\n",
      "FAKE: `` hall life record own still operation hit simply members bill least hot christian good yes you field where mrs. reached believe union finally use above SCORE: -8.043996633364602\n",
      "Enter your sentence:\n",
      "n\n",
      "Sorry, the words are not in the vocabulary\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # load data\n",
    "  # sentences are already converted to sequences of word indexes\n",
    "  # limit the vocab size if run out of memory\n",
    "  sentences, word2idx = get_sentences_with_word2idx_limit_vocab(1000)\n",
    "  # sentences, word2idx = get_sentences_with_word2idx()\n",
    "\n",
    "  # vocab size\n",
    "  V = len(word2idx)\n",
    "  print(\"Vocab size:\", V)\n",
    "\n",
    "  # treat beginning and end of sentence as bigrams, START -> first word, last word -> END\n",
    "  start_idx = word2idx['START']\n",
    "  end_idx = word2idx['END']\n",
    "\n",
    "\n",
    "  # a matrix where:\n",
    "  # row = last word\n",
    "  # col = current word\n",
    "  # value at [row, col] = p(current word | last word)\n",
    "  bigram_probs = get_bigram_probs(sentences, V, start_idx, end_idx, smoothing=0.1)\n",
    "\n",
    "\n",
    "  # a function to calculate normalized log prob score\n",
    "  # for a sentence\n",
    "  def get_score(sentence):\n",
    "    score = 0\n",
    "    for i in range(len(sentence)):\n",
    "      if i == 0:\n",
    "        # beginning word\n",
    "        score += np.log(bigram_probs[start_idx, sentence[i]])\n",
    "      else:\n",
    "        # middle word\n",
    "        score += np.log(bigram_probs[sentence[i-1], sentence[i]])\n",
    "    # final word\n",
    "    score += np.log(bigram_probs[sentence[-1], end_idx])\n",
    "\n",
    "    # normalize the score\n",
    "    return score / (len(sentence) + 1)\n",
    "\n",
    "\n",
    "  # a function to map word indexes back to real words\n",
    "  idx2word = dict((v, k) for k, v in iteritems(word2idx))\n",
    "  def get_words(sentence):\n",
    "    return ' '.join(idx2word[i] for i in sentence)\n",
    "\n",
    "\n",
    "  # when sample a fake sentence, ensure not to sample start token or end token\n",
    "  sample_probs = np.ones(V)\n",
    "  sample_probs[start_idx] = 0\n",
    "  sample_probs[end_idx] = 0\n",
    "  sample_probs /= sample_probs.sum()\n",
    "\n",
    "  # test model on real and fake sentences\n",
    "  while True:\n",
    "    # real sentence\n",
    "    real_idx = np.random.choice(len(sentences))\n",
    "    real = sentences[real_idx]\n",
    "\n",
    "    # fake sentence\n",
    "    fake = np.random.choice(V, size=len(real), p=sample_probs)\n",
    "\n",
    "    print(\"REAL:\", get_words(real), \"SCORE:\", get_score(real))\n",
    "    print(\"FAKE:\", get_words(fake), \"SCORE:\", get_score(fake))\n",
    "\n",
    "    # input your own sentence\n",
    "    custom = input(\"Enter your sentence:\\n\")\n",
    "    custom = custom.lower().split()\n",
    "\n",
    "    # check all tokens exist in word2idx (otherwise,can't get score)\n",
    "    bad_sentence = False\n",
    "    for token in custom:\n",
    "      if token not in word2idx:\n",
    "        bad_sentence = True\n",
    "\n",
    "    if bad_sentence:\n",
    "      print(\"Sorry, the words are not in the vocabulary\")\n",
    "    else:\n",
    "      # convert sentence into list of indexes\n",
    "      custom = [word2idx[token] for token in custom]\n",
    "      print(\"SCORE:\", get_score(custom))\n",
    "\n",
    "\n",
    "    cont = input(\"Continue? [Y/n]\")\n",
    "    if cont and cont.lower() in ('N', 'n'):\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
